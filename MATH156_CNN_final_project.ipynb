{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c85288-649b-48ab-a999-517a60bce3c1",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a78ce62e-1bcf-4d8e-9816-961ba4390427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tensorflow\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from pympler import asizeof\n",
    "import tensorflow_datasets as tfds\n",
    "import psutil\n",
    "from tensorflow import keras\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b70df-bb5f-4d38-8cbd-7f5663b6d6d7",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f035fdf2-8d70-467e-b558-e99fdae26548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "# Save the model at the end?\n",
    "save_model = False\n",
    "\n",
    "# Batch sizes for training and testing\n",
    "batch_size = 64\n",
    "test_batch_size = 14\n",
    "\n",
    "# Training epochs\n",
    "n_epochs = 5\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1.0\n",
    "\n",
    "# Decay rate for adjusting the learning rate\n",
    "gamma = 0.7\n",
    "\n",
    "# Number of target classes in the MNIST data\n",
    "num_classes = 10\n",
    "\n",
    "# Data input shape\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b3843fd-9289-4534-b105-884663c611de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# The scaled mean and standard deviation of the MNIST dataset (precalculated)\n",
    "data_mean = 0.1307\n",
    "data_std = 0.3081\n",
    "\n",
    "# Reshape the input data\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                        x_test.shape[1], \n",
    "                        x_test.shape[2], 1)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = (x_train/255.0 - data_mean) / data_std\n",
    "x_test = (x_test/255.0 - data_mean) / data_std\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "y_train = tf.one_hot(y_train.astype(np.int32), depth=num_classes)\n",
    "y_test = tf.one_hot(y_test.astype(np.int32), depth=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5234814-f4a1-4ba5-b1e9-a9561a7d7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture of the neural network\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), strides=(1,1),\n",
    "                                      padding='valid', \n",
    "                                      activation='relu',\n",
    "                                      input_shape=input_shape),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), strides=(1,1),\n",
    "                                      padding='valid',\n",
    "                                      activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ca5be68-ea74-4b88-830d-e55d7c7a897f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 12, 12, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1199882 (4.58 MB)\n",
      "Trainable params: 1199882 (4.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decay the learning rate at a base rate of gamma roughly every epoch, which\n",
    "# is len(x_train) steps\n",
    "scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    learning_rate,\n",
    "    decay_steps=len(x_train),\n",
    "    decay_rate=gamma)\n",
    "\n",
    "# Define the optimizer to user for gradient descent\n",
    "optimizer = tf.keras.optimizers.legacy.Adadelta(scheduler)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Display a model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9b4d676-65cf-405c-9af7-4e446ed2869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 38s 40ms/step - loss: 0.1826 - acc: 0.9447 - val_loss: 0.0469 - val_acc: 0.9846\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 37s 39ms/step - loss: 0.0739 - acc: 0.9785 - val_loss: 0.0353 - val_acc: 0.9881\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 37s 39ms/step - loss: 0.0546 - acc: 0.9837 - val_loss: 0.0368 - val_acc: 0.9883\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 37s 40ms/step - loss: 0.0460 - acc: 0.9863 - val_loss: 0.0323 - val_acc: 0.9895\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 37s 39ms/step - loss: 0.0402 - acc: 0.9878 - val_loss: 0.0292 - val_acc: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a6631750>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cpu_usage():\n",
    "    return psutil.cpu_percent(interval=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          validation_batch_size=test_batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
